{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9588406",
   "metadata": {},
   "source": [
    "# Selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873c40d",
   "metadata": {},
   "source": [
    "**¿Qué es la selección de características?**\n",
    "\n",
    "El objetivo de la selección de características es mejorar la interpretabilidad de los modelos, acelerar el proceso de aprendizaje y aumentar el rendimiento predictivo.\n",
    "\n",
    "**¿Cuándo deberíamos reducir el número de características utilizadas por nuestro modelo?**\n",
    "\n",
    "Algunos casos en los que es necesaria la selección de caracteristicas:\n",
    "\n",
    "- Cuando hay una fuerte colinealidad entre las características.\n",
    "\n",
    "- Hay una cantidad abrumadora de características.\n",
    "\n",
    "- No hay suficiente poder computacional para procesar todas las características.\n",
    "\n",
    "- El algoritmo obliga al modelo a usar todas las características, incluso cuando no son útiles (más a menudo en modelos paramétricos o lineales).\n",
    "\n",
    "- Cuando queremos simplificar el modelo por cualquier motivo. Por ejemplo, para que sea más fácil de explicar, se necesita menos potencia de cálculo.\n",
    "\n",
    "**¿Cuándo es innecesaria la selección de características?**\n",
    "\n",
    "Algunos casos en los que la selección de características no es necesaria:\n",
    "\n",
    "- Hay relativamente pocas características.\n",
    "\n",
    "- Todas las características contienen señales útiles e importantes.\n",
    "\n",
    "- No hay colinealidad entre las características.\n",
    "\n",
    "- El modelo seleccionará automáticamente las características más útiles.\n",
    "\n",
    "- Los recursos informáticos pueden manejar el procesamiento de todas las características.\n",
    "\n",
    "- Explicar a fondo el modelo a una audiencia no técnica no es fundamental.\n",
    "\n",
    "**¿Cuáles son los tres tipos de métodos de selección de características?**\n",
    "\n",
    "- Métodos de filtrado: la selección de características se realiza independientemente del algoritmo de aprendizaje, antes de realizar cualquier modelado. Un ejemplo es encontrar la correlación entre cada característica y el objetivo y descartar aquellas que no alcanzan un umbral. Fácil, rápido, pero ingenuo y no tan eficaz como otros métodos.\n",
    "\n",
    "    - Método básico.\n",
    "\n",
    "    - Método de correlación.\n",
    "    \n",
    "    - Métodos estadísticos (Ganancia de información / Chi Square / ANOVA).\n",
    "\n",
    "- Métodos de envoltorio: entrena modelos en subconjuntos de características y usa el subconjunto que resulte en el mejor rendimiento. Algunos ejemplos son la selección de características por Pasos o Recursiva. Las ventajas son que considera cada característica en el contexto de las otras características, pero puede ser computacionalmente costoso.\n",
    "\n",
    "    - Selección de avance.\n",
    "\n",
    "    - Eliminación hacia atrás.\n",
    "\n",
    "    - Búsqueda exhaustiva.\n",
    "\n",
    "- Métodos incorporados: los algoritmos de aprendizaje tienen una selección de características incorporada. Por ejemplo: regularización L1.\n",
    "\n",
    "    - Regularización LASSO.\n",
    "    \n",
    "    - Importancias de las características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9fa058",
   "metadata": {},
   "source": [
    "Usa lo siguiente [notebook](https://github.com/priyamnagar/feature_selection_titanic/blob/master/Titanic.ipynb) para ver cómo aplicar cada uno de estos métodos en un conjunto de datos que ya se ha dividido en conjuntos de entrenamiento y validación.\n",
    "\n",
    "Considera los siguientes enlaces para métodos estadísticos si planeas aplicar la selección de características:\n",
    "\n",
    "-[Chi square test](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2)\n",
    "\n",
    "-[Anova](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "\n",
    "-[Mutual Information](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
